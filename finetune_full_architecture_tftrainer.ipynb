{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m-newhauser/rep-or-dem-tweets/blob/main/finetune_full_architecture_tftrainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jClCIs_KmdSN"
      },
      "source": [
        "Resources\n",
        "\n",
        "* [Fine-tuning DistilBERT with TF (freezing last hidden layer from DistilBERT models)](https://towardsdatascience.com/hugging-face-transformers-fine-tuning-distilbert-for-binary-classification-tasks-490f1d192379)\n",
        "* [Fine-tuning DistilBERT with only TF](https://medium.com/geekculture/hugging-face-distilbert-tensorflow-for-custom-text-classification-1ad4a49e26a7)\n",
        "\n",
        "* [Fine-tuning multi-class BERT in PyTorch](https://colab.research.google.com/drive/18vy67le2DC-iMJK-AiB0vVKtMRAxmBnB?usp=sharing#scrollTo=4c81NkyZYCab)\n",
        "\n",
        "* [TFTrain DistilBERT](https://wandb.ai/ayush-thakur/huggingface/reports/How-to-Fine-Tune-Hugging-Face-Transformers-with-Weights-Biases---Vmlldzo0MzQ2MDc)\n",
        "\n",
        "* [Minimal code example to fine-tune BERT (and save to S3)](https://engineering.freeagent.com/2021/09/15/fine-tuning-bert-for-multiclass-categorisation-with-amazon-sagemaker/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GYEzXUtssbda"
      },
      "outputs": [],
      "source": [
        "# Install if necessary\n",
        "try:\n",
        "    import transformers\n",
        "    import preprocessor as p\n",
        "except ImportError:\n",
        "    print('Installing packages')\n",
        "    !pip install transformers==4.6.0\n",
        "    !pip install tweet-preprocessor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GP6Ij2iZsoaF"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "import preprocessor as p\n",
        "\n",
        "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
        "from transformers import (\n",
        "    TFDistilBertForSequenceClassification,\n",
        "    TFTrainer,\n",
        "    TFTrainingArguments,\n",
        ")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "random.seed(123)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNQKfYREyEY9",
        "outputId": "3c8eccb7-d3f5-4c53-b301-cabfd8ad0544"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqK4hXQJ7FCR"
      },
      "source": [
        "## Pre-process data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "A5ziNZObd164"
      },
      "outputs": [],
      "source": [
        "# Read in raw data -- https://fivethirtyeight.datasettes.com/fivethirtyeight/twitter-ratio%2Fsenators#export\n",
        "# tweets_raw = pd.read_csv(\"senators.csv\")\n",
        "\n",
        "# # Save to parquet (only have to do this the first time)\n",
        "# tweets_raw.to_parquet(\"senators.parquet\")\n",
        "\n",
        "tweets_raw = pd.read_parquet(\"/content/drive/MyDrive/Colab Data/senators.parquet\").sample(n=10000, random_state=123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KFMU-CsPanjK"
      },
      "outputs": [],
      "source": [
        "# Remove numbers, emojis and &'s\n",
        "p.set_options(p.OPT.NUMBER, p.OPT.EMOJI)\n",
        "\n",
        "tweets = (tweets_raw\n",
        "          .drop(columns=[\"created_at\", \"url\", \"bioguide_id\"])\n",
        "          .assign(\n",
        "              text_clean=tweets_raw[\"text\"].apply(p.clean).str.replace(\"&amp;\", \"and \").str[:512], # remove &'s and truncate\n",
        "              party=np.where(tweets_raw.user == \"SenSanders\", \"D\", tweets_raw.party) # Change Bernie Sanders from I --> D\n",
        "              )\n",
        "          .query('party != \"I\"') # Remove tweets from Independent senators\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print some info about the dataset\n",
        "print(f\"{tweets.shape[0]} total tweets in dataset\\n\")\n",
        "\n",
        "print(f\"Tweets by party:\\n{tweets.party.value_counts()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5juTkF2KzDqk",
        "outputId": "038ffb8a-8e4f-486c-8349-5a88b46f438d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9894 total tweets in dataset\n",
            "\n",
            "Tweets by party:\n",
            "R    5013\n",
            "D    4881\n",
            "Name: party, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "suYnas2CYm0O"
      },
      "outputs": [],
      "source": [
        "# Create a column with numeric labels\n",
        "label_mapping = {\n",
        "    \"D\": 0,\n",
        "    \"R\": 1\n",
        "}\n",
        "\n",
        "tweets['label'] = np.where(tweets['party'] == \"D\", 0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "QTqSv2n6jPjc"
      },
      "outputs": [],
      "source": [
        "# Convert to list\n",
        "texts = list(tweets.text_clean)\n",
        "labels = list(tweets.label)\n",
        "\n",
        "# Split training dataset into test and train\n",
        "(train_texts, test_texts, train_labels, test_labels) = train_test_split(\n",
        "    texts, labels, test_size=0.3\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qc0kPaxJ7Nlr"
      },
      "source": [
        "### Tokenize data for DistilBERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6_MnqOr2tmuv"
      },
      "outputs": [],
      "source": [
        "# Load DistilBERT tokenizer and tokenize (encode) the texts\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
        "test_encodings = tokenizer(test_texts, truncation=True, padding=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MDqepRg-m5D"
      },
      "source": [
        "### Create encodings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Qot-5NA0VOgG"
      },
      "outputs": [],
      "source": [
        "# Wrap encodings in a Tensor Flow dataset\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(train_encodings),\n",
        "    train_labels\n",
        "))\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(test_encodings),\n",
        "    test_labels\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-Nld6gI-xoG"
      },
      "source": [
        "## Fine-tune entire DistilBERT architecture (layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSCu1830s6Sx",
        "outputId": "34b84c70-582c-430c-aad2-407e66c1795f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_transform', 'activation_13', 'vocab_projector', 'vocab_layer_norm']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['dropout_19', 'pre_classifier', 'classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Create a dict of metrics to calculate during training\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n",
        "\n",
        "\n",
        "# Provide args for fine-tuning DistilBERT on our data\n",
        "training_args = TFTrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=5,              # total # of training epochs\n",
        "    per_device_train_batch_size=32,  # batch size per device during training\n",
        "    per_device_eval_batch_size=32,   # batch size for evaluation\n",
        "    learning_rate=2e-05,             # start with a low learning rate when fine-tuning\n",
        "    warmup_steps=250,                # number of warmup steps for learning rate scheduler ([500, 1000] are normal but start low)\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=1,\n",
        "    eval_steps=10\n",
        ")\n",
        "\n",
        "# Instantiate the pre-trained model\n",
        "with training_args.strategy.scope():\n",
        "    model = TFDistilBertForSequenceClassification.from_pretrained(\n",
        "        \"distilbert-base-uncased\", \n",
        "        num_labels=2\n",
        "    )\n",
        "\n",
        "# Create the trainer\n",
        "trainer = TFTrainer(\n",
        "    model=model,  # the instantiated ðŸ¤— Transformers model to be trained\n",
        "    args=training_args,  # training arguments, defined above\n",
        "    train_dataset=train_dataset,  # training dataset\n",
        "    eval_dataset=test_dataset,  # evaluation dataset,\n",
        "    compute_metrics=compute_metrics # custom function with metrics to compute\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "weHFBpPys9RC"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "HNEo13hy_0mW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f272780-988a-4665-c6a0-6b5de1a2f384"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7fbf7fbdc910>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7fbf7fbdc910>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7fbf9aec5c20> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function wrap at 0x7fbf9aec5c20> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_accuracy': 0.9348118279569892,\n",
              " 'eval_f1': 0.938685208596713,\n",
              " 'eval_loss': 0.19751085260862944,\n",
              " 'eval_precision': 0.928125,\n",
              " 'eval_recall': 0.9494884910485933}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "trainer.save_model(\"/content/drive/MyDrive/Colab Data/models/finetune-distilbert-senators\")"
      ],
      "metadata": {
        "id": "uMKLGgPix6hc"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set\n",
        "test_predictions = trainer.predict(test_dataset)\n",
        "\n",
        "# Apply softmax to get final predicted labels for test set\n",
        "test_predictions_labels = test_predictions.predictions.argmax(-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ec65rLs7yceu",
        "outputId": "d681fd43-1766-4610-e4b7-eff0b15fd7fc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an output dataframe with truth and predicted labels on test set\n",
        "predictions_df = pd.DataFrame({\n",
        "    \"text\": test_texts,\n",
        "    \"label\": test_labels,\n",
        "    \"pred\": test_predictions_labels\n",
        "})\n",
        "\n",
        "# Now merge it with other Twitter information\n",
        "predictions_df = (tweets[[\"rowid\", \"user\", \"state\", \"party\", \"text_clean\"]]\n",
        "                  .merge(predictions_df, left_on=\"text_clean\", right_on=\"text\")\n",
        "                  .drop(columns=[\"text_clean\"])\n",
        "                  )"
      ],
      "metadata": {
        "id": "PkxPEikx0Ius"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy by party\n",
        "(predictions_df\n",
        " .groupby(\"party\")\n",
        " .apply(lambda x: accuracy_score(x[\"label\"], x[\"pred\"]))\n",
        " )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4C01sMlhCvMD",
        "outputId": "31929731-d600-4568-cc16-68871ab15e3c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "party\n",
              "D    0.918977\n",
              "R    0.949424\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy by state\n",
        "(predictions_df\n",
        " .groupby(\"state\")\n",
        " .apply(lambda x: accuracy_score(x[\"label\"], x[\"pred\"]))\n",
        " .sort_values()\n",
        " )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1UQf13dDfpG",
        "outputId": "ac0fcee5-7eab-42af-d93b-c2a6b109014c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "state\n",
              "FL    0.818182\n",
              "WV    0.830769\n",
              "CO    0.836066\n",
              "ND    0.862745\n",
              "OH    0.865385\n",
              "MS    0.891892\n",
              "CA    0.891892\n",
              "MI    0.897059\n",
              "AZ    0.902439\n",
              "MD    0.907407\n",
              "AR    0.910256\n",
              "NE    0.914894\n",
              "RI    0.915493\n",
              "MA    0.916667\n",
              "NY    0.916667\n",
              "IL    0.916667\n",
              "NV    0.926829\n",
              "MT    0.928571\n",
              "IA    0.930233\n",
              "MO    0.933333\n",
              "DE    0.934211\n",
              "LA    0.934783\n",
              "VA    0.935065\n",
              "NC    0.935484\n",
              "WI    0.937500\n",
              "NH    0.938462\n",
              "CT    0.938776\n",
              "NJ    0.940299\n",
              "GA    0.942029\n",
              "OR    0.942029\n",
              "IN    0.943662\n",
              "HI    0.951220\n",
              "NM    0.951613\n",
              "OK    0.952381\n",
              "AK    0.955556\n",
              "VT    0.955882\n",
              "AL    0.956522\n",
              "KY    0.959459\n",
              "TX    0.961538\n",
              "WY    0.961538\n",
              "MN    0.965517\n",
              "ID    0.966102\n",
              "WA    0.969231\n",
              "KS    0.970588\n",
              "PA    0.971014\n",
              "SD    0.971014\n",
              "TN    0.985075\n",
              "UT    0.987179\n",
              "ME    1.000000\n",
              "SC    1.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy by user\n",
        "(predictions_df\n",
        " .groupby(\"user\")\n",
        " .apply(lambda x: accuracy_score(x[\"label\"], x[\"pred\"]))\n",
        " .sort_values()\n",
        " )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6aYaB-zDwe0",
        "outputId": "1427efe0-f2f5-4014-a03d-67f6b3dfbf2f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "user\n",
              "SenBillNelson      0.428571\n",
              "SenBennetCO        0.720000\n",
              "Sen_JoeManchin     0.757576\n",
              "SenatorHeitkamp    0.760000\n",
              "SenCortezMasto     0.800000\n",
              "                     ...   \n",
              "SenDeanHeller      1.000000\n",
              "SenatorCollins     1.000000\n",
              "LindseyGrahamSC    1.000000\n",
              "SenPatRoberts      1.000000\n",
              "McConnellPress     1.000000\n",
              "Length: 99, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "finetune_full_architecture_tftrainer.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO+ONFfgAddGFZoK1Jgl4P8",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}