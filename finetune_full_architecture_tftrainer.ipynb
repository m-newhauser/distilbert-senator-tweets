{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m-newhauser/rep-or-dem-tweets/blob/main/finetune_full_architecture_tftrainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jClCIs_KmdSN"
      },
      "source": [
        "Resources\n",
        "\n",
        "* [Fine-tuning DistilBERT with TF (freezing last hidden layer from DistilBERT models)](https://towardsdatascience.com/hugging-face-transformers-fine-tuning-distilbert-for-binary-classification-tasks-490f1d192379)\n",
        "* [Fine-tuning DistilBERT with only TF](https://medium.com/geekculture/hugging-face-distilbert-tensorflow-for-custom-text-classification-1ad4a49e26a7)\n",
        "\n",
        "* [Fine-tuning multi-class BERT in PyTorch](https://colab.research.google.com/drive/18vy67le2DC-iMJK-AiB0vVKtMRAxmBnB?usp=sharing#scrollTo=4c81NkyZYCab)\n",
        "\n",
        "* [TFTrain DistilBERT](https://wandb.ai/ayush-thakur/huggingface/reports/How-to-Fine-Tune-Hugging-Face-Transformers-with-Weights-Biases---Vmlldzo0MzQ2MDc)\n",
        "\n",
        "* [Minimal code example to fine-tune BERT (and save to S3)](https://engineering.freeagent.com/2021/09/15/fine-tuning-bert-for-multiclass-categorisation-with-amazon-sagemaker/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYEzXUtssbda",
        "outputId": "8c6619fb-30eb-42a6-d649-1aeafbe87a24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers==4.6.0 in /usr/local/lib/python3.7/dist-packages (4.6.0)\n",
            "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0) (0.0.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0) (0.0.46)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0) (3.4.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0) (0.10.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0) (4.8.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0) (4.62.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.6.0) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.6.0) (3.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.6.0) (3.0.6)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.0) (2021.10.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.6.0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.6.0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.6.0) (1.1.0)\n",
            "Requirement already satisfied: tweet-preprocessor in /usr/local/lib/python3.7/dist-packages (0.6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==4.6.0\n",
        "!pip install tweet-preprocessor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GP6Ij2iZsoaF"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "import preprocessor as p\n",
        "\n",
        "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
        "from transformers import (\n",
        "    TFDistilBertForSequenceClassification,\n",
        "    TFTrainer,\n",
        "    TFTrainingArguments,\n",
        ")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "\n",
        "random.seed(123)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqK4hXQJ7FCR"
      },
      "source": [
        "## Pre-process data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "A5ziNZObd164"
      },
      "outputs": [],
      "source": [
        "# Read in raw data -- https://fivethirtyeight.datasettes.com/fivethirtyeight/twitter-ratio%2Fsenators#export\n",
        "# tweets_raw = pd.read_csv(\"senators.csv\")\n",
        "tweets_raw = pd.read_parquet(\"senators.parquet\").sample(n=10000, random_state=123)\n",
        "\n",
        "# # Save to parquet (only have to do this the first time)\n",
        "# tweets_raw.to_parquet(\"senators.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "KFMU-CsPanjK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c83f0df-f9ac-4c5b-a2b5-3e4e560841c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9894, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# Remove numbers, emojis and &'s\n",
        "p.set_options(p.OPT.NUMBER, p.OPT.EMOJI)\n",
        "\n",
        "tweets = (tweets_raw\n",
        "          .drop(columns=[\"created_at\", \"url\", \"bioguide_id\"])\n",
        "          .assign(\n",
        "              text_clean=tweets_raw[\"text\"].apply(p.clean).str.replace(\"&amp;\", \"and \").str[:512], # remove &'s and truncate\n",
        "              party=np.where(tweets_raw.user == \"SenSanders\", \"D\", tweets_raw.party) # Change Bernie Sanders from I --> D\n",
        "              )\n",
        "          .query('party != \"I\"') # Remove tweets from Independent senators\n",
        "          )\n",
        "\n",
        "tweets.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "suYnas2CYm0O"
      },
      "outputs": [],
      "source": [
        "# Create a column with numeric labels\n",
        "label_mapping = {\n",
        "    \"D\": 0,\n",
        "    \"R\": 1\n",
        "}\n",
        "\n",
        "tweets['label'] = np.where(tweets['party'] == \"D\", 0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "QTqSv2n6jPjc"
      },
      "outputs": [],
      "source": [
        "# Convert to list\n",
        "texts = list(tweets.text_clean)\n",
        "labels = list(tweets.label)\n",
        "\n",
        "# Split training dataset into test and train\n",
        "(train_texts, test_texts, train_labels, test_labels) = train_test_split(\n",
        "    texts, labels, test_size=0.3\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qc0kPaxJ7Nlr"
      },
      "source": [
        "### Tokenize data for DistilBERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "6_MnqOr2tmuv"
      },
      "outputs": [],
      "source": [
        "# Load DistilBERT tokenizer and tokenize (encode) the texts\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
        "test_encodings = tokenizer(test_texts, truncation=True, padding=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MDqepRg-m5D"
      },
      "source": [
        "### Create encodings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Qot-5NA0VOgG"
      },
      "outputs": [],
      "source": [
        "# Wrap encodings in a Tensor Flow dataset\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(train_encodings),\n",
        "    train_labels\n",
        "))\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(test_encodings),\n",
        "    test_labels\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-Nld6gI-xoG"
      },
      "source": [
        "## Fine-tune entire DistilBERT architecture (layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSCu1830s6Sx",
        "outputId": "8df9e77e-5a2a-412a-fc3f-d19162414159"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_transform', 'vocab_layer_norm', 'vocab_projector', 'activation_13']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier', 'classifier', 'dropout_39']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Create a dict of metrics to calculate during training\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n",
        "\n",
        "\n",
        "# Provide args for fine-tuning DistilBERT on our data\n",
        "training_args = TFTrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=5,              # total # of training epochs\n",
        "    per_device_train_batch_size=32,  # batch size per device during training\n",
        "    per_device_eval_batch_size=32,   # batch size for evaluation\n",
        "    learning_rate=2e-05,             # start with a low learning rate when fine-tuning\n",
        "    warmup_steps=250,                # number of warmup steps for learning rate scheduler ([500, 1000] are normal but start low)\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=1,\n",
        "    eval_steps=10\n",
        ")\n",
        "\n",
        "# Instantiate the pre-trained model\n",
        "with training_args.strategy.scope():\n",
        "    model = TFDistilBertForSequenceClassification.from_pretrained(\n",
        "        \"distilbert-base-uncased\", \n",
        "        num_labels=2\n",
        "    )\n",
        "\n",
        "# Create the trainer\n",
        "trainer = TFTrainer(\n",
        "    model=model,  # the instantiated ðŸ¤— Transformers model to be trained\n",
        "    args=training_args,  # training arguments, defined above\n",
        "    train_dataset=train_dataset,  # training dataset\n",
        "    eval_dataset=test_dataset,  # evaluation dataset,\n",
        "    compute_metrics=compute_metrics # custom function with metrics to compute\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "weHFBpPys9RC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b64445e4-2d7e-4f55-d083-d8e3cfd78b81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "HNEo13hy_0mW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7597831-0ab0-4495-cd83-62960830e5a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_accuracy': 0.8780241935483871,\n",
              " 'eval_f1': 0.8843580758203249,\n",
              " 'eval_loss': 0.31257635547268775,\n",
              " 'eval_precision': 0.8696741854636592,\n",
              " 'eval_recall': 0.899546338302009}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "trainer.save_model(\"finetune-distilbert-senators\")"
      ],
      "metadata": {
        "id": "uMKLGgPix6hc"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set\n",
        "test_predictions = trainer.predict(test_dataset)\n",
        "\n",
        "# Apply softmax to get final predicted labels for test set\n",
        "test_predictions_labels = test_predictions.predictions.argmax(-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ec65rLs7yceu",
        "outputId": "48c2e9b6-2ec5-49fe-bb1e-cdc02cbf4547"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an output dataframe with truth and predicted labels on test set\n",
        "predictions_df = pd.DataFrame({\n",
        "    \"text\": test_texts,\n",
        "    \"label\": test_labels,\n",
        "    \"pred\": test_predictions_labels\n",
        "})\n",
        "\n",
        "# Now merge it with other Twitter information\n",
        "predictions_df = (tweets[[\"rowid\", \"user\", \"state\", \"party\", \"text_clean\"]]\n",
        "                  .merge(predictions_df, left_on=\"text_clean\", right_on=\"text\")\n",
        "                  .drop(columns=[\"text_clean\"])\n",
        "                  )"
      ],
      "metadata": {
        "id": "PkxPEikx0Ius"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy by party\n",
        "(predictions_df\n",
        " .groupby(\"party\")\n",
        " .apply(lambda x: accuracy_score(x[\"label\"], x[\"pred\"]))\n",
        " )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4C01sMlhCvMD",
        "outputId": "bbda7fe3-f245-431d-9e7f-4e0891a86bd3"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "party\n",
              "D    0.854647\n",
              "R    0.899285\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy by state\n",
        "(predictions_df\n",
        " .groupby(\"state\")\n",
        " .apply(lambda x: accuracy_score(x[\"label\"], x[\"pred\"]))\n",
        " .sort_values()\n",
        " )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1UQf13dDfpG",
        "outputId": "4d0003cb-030b-4cc9-d0b3-2b3348e101a9"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "state\n",
              "WV    0.705128\n",
              "OH    0.706897\n",
              "LA    0.717391\n",
              "NH    0.777778\n",
              "VT    0.779661\n",
              "VA    0.787879\n",
              "NV    0.823529\n",
              "DE    0.823529\n",
              "HI    0.833333\n",
              "TX    0.836364\n",
              "RI    0.850000\n",
              "MT    0.860759\n",
              "MD    0.860759\n",
              "CO    0.862069\n",
              "CA    0.862745\n",
              "SC    0.866667\n",
              "NM    0.868852\n",
              "IA    0.869565\n",
              "AK    0.869565\n",
              "OR    0.870370\n",
              "NE    0.872340\n",
              "IL    0.876923\n",
              "PA    0.881356\n",
              "MO    0.888889\n",
              "MA    0.891892\n",
              "MI    0.892308\n",
              "SD    0.893617\n",
              "WA    0.901639\n",
              "ND    0.901961\n",
              "NC    0.906250\n",
              "NY    0.907692\n",
              "UT    0.909091\n",
              "NJ    0.910256\n",
              "MN    0.910448\n",
              "ID    0.911111\n",
              "TN    0.913043\n",
              "GA    0.913043\n",
              "AL    0.920000\n",
              "WY    0.922078\n",
              "KS    0.930556\n",
              "KY    0.933333\n",
              "CT    0.933333\n",
              "AR    0.942308\n",
              "MS    0.943396\n",
              "AZ    0.945205\n",
              "FL    0.952381\n",
              "ME    0.956522\n",
              "OK    0.963636\n",
              "WI    0.969231\n",
              "IN    0.970149\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy by user\n",
        "(predictions_df\n",
        " .groupby(\"user\")\n",
        " .apply(lambda x: accuracy_score(x[\"label\"], x[\"pred\"]))\n",
        " .sort_values()\n",
        " )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6aYaB-zDwe0",
        "outputId": "5ff84dcf-075b-493b-d13c-623bd2ab833b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "user\n",
              "Sen_JoeManchin     0.636364\n",
              "SenatorStrange     0.666667\n",
              "SenatorShaheen     0.666667\n",
              "senrobportman      0.666667\n",
              "SenatorLeahy       0.714286\n",
              "                     ...   \n",
              "SenPatRoberts      0.975000\n",
              "McConnellPress     1.000000\n",
              "SenJoniErnst       1.000000\n",
              "JeffFlake          1.000000\n",
              "SenMurphyOffice    1.000000\n",
              "Length: 99, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "finetune_full_architecture_tftrainer.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO4XjbdgcxlqmUklu2xj4Gr",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}